---
annotation-target: s41551-022-00936-9.pdf
---


>%%
>```annotation-json
>{"created":"2022-09-17T01:50:10.738Z","updated":"2022-09-17T01:50:10.738Z","document":{"title":"Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning","link":[{"href":"urn:x-pdf:244c2ce92d3cc14c9d2973616ee2d946"},{"href":"vault:/hematology-theroy/papers/20220830andrewng/s41551-022-00936-9.pdf"}],"documentFingerprint":"244c2ce92d3cc14c9d2973616ee2d946"},"uri":"vault:/hematology-theroy/papers/20220830andrewng/s41551-022-00936-9.pdf","target":[{"source":"vault:/hematology-theroy/papers/20220830andrewng/s41551-022-00936-9.pdf","selector":[{"type":"TextPositionSelector","start":369,"end":2038},{"type":"TextQuoteSelector","exact":"Deep learning has enabled the automation of complex medi-cal  image  interpretation  tasks,  such  as  disease  diagnosis,  often  matching  or  exceeding  the  performance  of  medical  experts1–5.  However,  despite  these  meaningful  improvements  in  diagnostic efficiency, automated deep learning models often require large  labelled  datasets  during  training6.  These  large-scale  labelling  efforts can be expensive and time consuming, often requiring exten-sive  domain  knowledge  or  technical  expertise  to  implement  for  a  particular medical task7,8.Several approaches such as model pre-training and self- supervision  have  been  proposed  to  decrease  model  reliance  on  large  labelled  datasets9–12.  Although  self-supervised  pre-training  approaches have been shown to increase label efficiency across sev-eral  medical  tasks,  they  still  require  a  supervised  fine-tuning  step  after pre-training that requires manually labelled data for the model to predict relevant pathologies13,14. As a result, these approaches are only  able  to  predict  diseases  that  were  explicitly  annotated  in  the  dataset, and are unable to predict pathologies that were not explic-itly annotated for training. Thus, for the model to predict a certain pathology  with  reasonable  performance,  it  must  be  provided  with  a  substantial  number  of  expert-labelled  training  examples  for  that  pathology  during  training.  This  process  of  obtaining  high-quality  annotations of certain pathologies is often costly and time consum-ing,  often  resulting  in  large-scale  inefficiencies  in  clinical  artificial  intelligence workflows","prefix":"pranav_rajpurkar@hms.harvard.edu","suffix":".In this Article, to address the"}]}]}
>```
>%%
>*%%PREFIX%%pranav_rajpurkar@hms.harvard.edu%%HIGHLIGHT%% ==Deep learning has enabled the automation of complex medi-cal  image  interpretation  tasks,  such  as  disease  diagnosis,  often  matching  or  exceeding  the  performance  of  medical  experts1–5.  However,  despite  these  meaningful  improvements  in  diagnostic efficiency, automated deep learning models often require large  labelled  datasets  during  training6.  These  large-scale  labelling  efforts can be expensive and time consuming, often requiring exten-sive  domain  knowledge  or  technical  expertise  to  implement  for  a  particular medical task7,8.Several approaches such as model pre-training and self- supervision  have  been  proposed  to  decrease  model  reliance  on  large  labelled  datasets9–12.  Although  self-supervised  pre-training  approaches have been shown to increase label efficiency across sev-eral  medical  tasks,  they  still  require  a  supervised  fine-tuning  step  after pre-training that requires manually labelled data for the model to predict relevant pathologies13,14. As a result, these approaches are only  able  to  predict  diseases  that  were  explicitly  annotated  in  the  dataset, and are unable to predict pathologies that were not explic-itly annotated for training. Thus, for the model to predict a certain pathology  with  reasonable  performance,  it  must  be  provided  with  a  substantial  number  of  expert-labelled  training  examples  for  that  pathology  during  training.  This  process  of  obtaining  high-quality  annotations of certain pathologies is often costly and time consum-ing,  often  resulting  in  large-scale  inefficiencies  in  clinical  artificial  intelligence workflows== %%POSTFIX%%.In this Article, to address the*
>%%LINK%%[[#^reeiog5v85g|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^reeiog5v85g


>%%
>```annotation-json
>{"created":"2022-09-17T01:51:00.402Z","updated":"2022-09-17T01:51:00.402Z","document":{"title":"Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning","link":[{"href":"urn:x-pdf:244c2ce92d3cc14c9d2973616ee2d946"},{"href":"vault:/hematology-theroy/papers/20220830andrewng/s41551-022-00936-9.pdf"}],"documentFingerprint":"244c2ce92d3cc14c9d2973616ee2d946"},"uri":"vault:/hematology-theroy/papers/20220830andrewng/s41551-022-00936-9.pdf","target":[{"source":"vault:/hematology-theroy/papers/20220830andrewng/s41551-022-00936-9.pdf","selector":[{"type":"TextPositionSelector","start":13810,"end":14253},{"type":"TextQuoteSelector","exact":"The purpose of this work was to develop and demonstrate perfor-mance  of  a  zero-shot  classification  method  for  medical  imaging  without  training  on  any  explicit  manual  or  annotated  labels.  The  results  show  that,  with  no  explicit  labels,  the  zero-shot  method  is  comparable to the performance of both expert radiologists and fully supervised methods on pathologies that were not explicitly labelled during  training. ","prefix":"  labels   are needed.discussion","suffix":" Specifically,  the  self-superv"}]}]}
>```
>%%
>*%%PREFIX%%labels   are needed.discussion%%HIGHLIGHT%% ==The purpose of this work was to develop and demonstrate perfor-mance  of  a  zero-shot  classification  method  for  medical  imaging  without  training  on  any  explicit  manual  or  annotated  labels.  The  results  show  that,  with  no  explicit  labels,  the  zero-shot  method  is  comparable to the performance of both expert radiologists and fully supervised methods on pathologies that were not explicitly labelled during  training.== %%POSTFIX%%Specifically,  the  self-superv*
>%%LINK%%[[#^u23g5fysnda|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^u23g5fysnda


>%%
>```annotation-json
>{"created":"2022-09-17T01:59:12.252Z","updated":"2022-09-17T01:59:12.252Z","document":{"title":"Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning","link":[{"href":"urn:x-pdf:244c2ce92d3cc14c9d2973616ee2d946"},{"href":"vault:/hematology-theroy/papers/20220830andrewng/s41551-022-00936-9.pdf"}],"documentFingerprint":"244c2ce92d3cc14c9d2973616ee2d946"},"uri":"vault:/hematology-theroy/papers/20220830andrewng/s41551-022-00936-9.pdf","target":[{"source":"vault:/hematology-theroy/papers/20220830andrewng/s41551-022-00936-9.pdf","selector":[{"type":"TextPositionSelector","start":14435,"end":15076},{"type":"TextQuoteSelector","exact":"We  also  show  that  the  performance  of  the  self-supervised  model  is  comparable  to  that  of  radiologists,  as  there  is  no  statistically  significant  differ-ence between the performance of the model and the performance of the radiologists on the average MCC and F1 over the five CheXpert competition  pathologies.  We  also  show  that  the  self-supervised  model  outperforms  previous  label-efficient  approaches  on  chest  X-ray  pathology  classification,  suggesting  that  explicit  labels  are  not required to perform well on medical-image-interpretation tasks when corresponding reports are available for training.","prefix":"n  the  CheXpert  competition.  ","suffix":" We achieved these  results  usi"}]}]}
>```
>%%
>*%%PREFIX%%n  the  CheXpert  competition.%%HIGHLIGHT%% ==We  also  show  that  the  performance  of  the  self-supervised  model  is  comparable  to  that  of  radiologists,  as  there  is  no  statistically  significant  differ-ence between the performance of the model and the performance of the radiologists on the average MCC and F1 over the five CheXpert competition  pathologies.  We  also  show  that  the  self-supervised  model  outperforms  previous  label-efficient  approaches  on  chest  X-ray  pathology  classification,  suggesting  that  explicit  labels  are  not required to perform well on medical-image-interpretation tasks when corresponding reports are available for training.== %%POSTFIX%%We achieved these  results  usi*
>%%LINK%%[[#^o38utpcmyb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^o38utpcmyb
